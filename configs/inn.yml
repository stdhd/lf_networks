experiment_id: sep_motion_batchnorm_start_encoder
experiment: secondstage
checkpoint_moitor: 'val/fvd_reconstruction'
model_save_dir: data/models
num_workers: 12
max_frames: 5
split: 0.5
split_direction: samples
loss: perceptual #reconstruction or perceptual
watch_gradients: False
first_stage_checkpoint: 'important_checkpoints/discafter_50_easy_hill/epoch=58-step=79767.ckpt'
first_stage_config: 'important_checkpoints/discafter_50_easy_hill/config.yml'
logging:
  video: True
  n_fvd_samples: 1000
  n_samples: 20
  bs_i3d: 8

latent_dimensions:
  pq_latent_size: 32
  pq_latent_dim: 8 # 64 x 3 x 3
  # Double the size is the latent output of hamiltonian unet

# Define networks architectures
networks:
  inn:
    conditional: True
    hidden_dim: 64
    hidden_depth: 2
    n_flows: 20
    activation: 'lrelu'

  condition_encoder:
    type: "standard"
    hidden_conv_layers: 2
    n_filters: [ 8, 12, 32 ]  # first + hidden
    kernel_sizes: [ 3, 3, 3, 3, 3 ]  # first + hidden + last
    strides: [ 1, 2, 2, 2, 2 ]  # first + hidden + last
    out_channels: 32 # TODO: Evaluate impact

# Define optimization
optimization:
  epochs: 50
  precision: 32
  batch_size: 35
  input_frames: 10  # Number of frames to feed to the encoder while training
  # Learning rates
  inn_lr: 1.5e-4
  gamma: 0.9 # scheduler
  weight_decay: 0.0001
  training_objective: 'prior'


# Define data characteristics
dataset:
  datakeys: ['images'] #['sequence']
  name: 'Bair'
  aug: False
  crop_to_size: 128
  data_path_local: /home/sd/Documents/thesis/hgn_natural/data/bair/bair/
  data_path: /export/scratch/compvis/datasets/bair/
  img_size: 64
  split: official
  sequence_length: 11
  spatial_size: !!python/tuple [64, 64]
  radius_bound: 'auto'
  normalize: True
  rollout:
    delta_time: 1
    n_channels: 3
    noise_level: 1  # Level of environment noise. 0 means no noise, 1 means max noise.
                    # Maximum values are defined in each environment.
